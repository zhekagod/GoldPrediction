{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2445315,"sourceType":"datasetVersion","datasetId":1479724}],"dockerImageVersionId":30120,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Learning Nanodegree","metadata":{}},{"cell_type":"markdown","source":"Hello Kagglers this notebook is part of my Capstone Project for Udacity ML Engineer Nanodegree Program. You can check my [repository](https://github.com/sid321axn/Udacity-MLND-Capstone-Gold-Price-Prediction) for full documentation about the project.","metadata":{}},{"cell_type":"markdown","source":"## Gold Rates Prediction using Machine Learning Approach","metadata":{}},{"cell_type":"markdown","source":"Historically, gold had been used as a form of currency in various parts of the world including USA. In present times, precious metals like gold are held with central banks of all countries to guarantee re-payment of foreign debts, and also to control inflation which results in reflecting the financial strength of the country. \n\nForecasting rise and fall in the daily gold rates, can help investors to decide when to buy (or sell) the commodity. \n\nWe in this project would forecast gold rates using the most comprehensive set of features and would apply various machine learning algorithms for forecasting and compare their results. We also identify the attributes that highly influence the gold rates.\n\n![Gold ETF](https://i.ibb.co/S07Np5F/Gold.png)\n\n\n![Gold ETF](https://i.ibb.co/S07Np5F/Gold.png)","metadata":{}},{"cell_type":"markdown","source":"\n## Project Work Flow\n\nI would proceed the project as shown in the below mentioned steps.\n\n\n![Project Work Flow](https://i.ibb.co/bbcVFwS/pd.png)","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.dates as mdates\nfrom sklearn import linear_model\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.svm import SVR\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:02.576935Z","iopub.execute_input":"2021-07-20T15:08:02.577282Z","iopub.status.idle":"2021-07-20T15:08:02.599166Z","shell.execute_reply.started":"2021-07-20T15:08:02.577253Z","shell.execute_reply":"2021-07-20T15:08:02.598251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## About Data","metadata":{}},{"cell_type":"markdown","source":"Data for this study is collected from **November 18th 2011** to **January 1st 2019** from various sources. The data has **1718** rows in total and **80** columns in total. Data for attributes, such as Oil Price, Standard and Poorâ€™s (S&P) 500 index, Dow Jones Index US Bond rates (10 years), Euro USD exchange rates, prices of precious metals Silver and Platinum and other metals such as Palladium and Rhodium, prices of  US Dollar Index, Eldorado Gold Corporation and Gold Miners ETF were gathered. \n\n**Attributes:**\n\n**Features**\n\n- Gold ETF :- Date, Open, High, Low, Close and Volume.\n- S&P 500 Index :- 'SP_open', 'SP_high', 'SP_low', 'SP_close', 'SP_Ajclose', 'SP_volume' \n- Dow Jones Index :- 'DJ_open','DJ_high', 'DJ_low', 'DJ_close', 'DJ_Ajclose', 'DJ_volume' \n- Eldorado Gold Corporation (EGO) :- 'EG_open', 'EG_high', 'EG_low', 'EG_close', 'EG_Ajclose', 'EG_volume'\n- EURO - USD Exchange Rate :- 'EU_Price','EU_open', 'EU_high', 'EU_low', 'EU_Trend' \n- Brent Crude Oil Futures :- 'OF_Price', 'OF_Open', 'OF_High', 'OF_Low', 'OF_Volume', 'OF_Trend'\n- Crude Oil WTI USD :- 'OS_Price', 'OS_Open', 'OS_High', 'OS_Low', 'OS_Trend'\n- Silver Futures :- 'SF_Price', 'SF_Open', 'SF_High', 'SF_Low', 'SF_Volume', 'SF_Trend'\n- US Bond Rate (10 years) :- 'USB_Price', 'USB_Open', 'USB_High','USB_Low', 'USB_Trend' \n- Platinum Price :- 'PLT_Price', 'PLT_Open', 'PLT_High', 'PLT_Low','PLT_Trend'\n- Palladium Price :- 'PLD_Price', 'PLD_Open', 'PLD_High', 'PLD_Low','PLD_Trend' \n- Rhodium Prices :- 'RHO_PRICE' \n- US Dollar Index : 'USDI_Price', 'USDI_Open', 'USDI_High','USDI_Low', 'USDI_Volume', 'USDI_Trend' \n- Gold Miners ETF :- 'GDX_Open', 'GDX_High', 'GDX_Low', 'GDX_Close', 'GDX_Adj Close', 'GDX_Volume' \n- Oil ETF USO :- 'USO_Open','USO_High', 'USO_Low', 'USO_Close', 'USO_Adj Close', 'USO_Volume'\n\n**Target Variable**\n- Gold ETF :- Adjusted Close","metadata":{}},{"cell_type":"code","source":"df_final = pd.read_csv(\"/kaggle/input/gold-price-prediction-dataset/FINAL_USO.csv\",na_values=['null'],index_col='Date',parse_dates=True,infer_datetime_format=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:15.821031Z","iopub.execute_input":"2021-07-20T15:08:15.821397Z","iopub.status.idle":"2021-07-20T15:08:15.909082Z","shell.execute_reply.started":"2021-07-20T15:08:15.821369Z","shell.execute_reply":"2021-07-20T15:08:15.908369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:16.876857Z","iopub.execute_input":"2021-07-20T15:08:16.877211Z","iopub.status.idle":"2021-07-20T15:08:16.913141Z","shell.execute_reply.started":"2021-07-20T15:08:16.877182Z","shell.execute_reply":"2021-07-20T15:08:16.912207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:17.340923Z","iopub.execute_input":"2021-07-20T15:08:17.3413Z","iopub.status.idle":"2021-07-20T15:08:17.346245Z","shell.execute_reply.started":"2021-07-20T15:08:17.341271Z","shell.execute_reply":"2021-07-20T15:08:17.345535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, we have 1718 records in the dataset and 80 columns including Adjusted Close which is our target variable.","metadata":{}},{"cell_type":"code","source":"df_final.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:18.357278Z","iopub.execute_input":"2021-07-20T15:08:18.357702Z","iopub.status.idle":"2021-07-20T15:08:18.521947Z","shell.execute_reply.started":"2021-07-20T15:08:18.357674Z","shell.execute_reply":"2021-07-20T15:08:18.521083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking Missing Values","metadata":{}},{"cell_type":"code","source":"df_final.isnull().values.any()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:19.520828Z","iopub.execute_input":"2021-07-20T15:08:19.521189Z","iopub.status.idle":"2021-07-20T15:08:19.52805Z","shell.execute_reply.started":"2021-07-20T15:08:19.521155Z","shell.execute_reply":"2021-07-20T15:08:19.526993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's great ! we dont have any missing values in our dataset","metadata":{}},{"cell_type":"markdown","source":"## Effect of Index prices on gold rates","metadata":{}},{"cell_type":"code","source":"GLD_adj_close = df_final['Adj Close']\nSPY_adj_close = df_final['SP_Ajclose']\nDJ_adj_close  = df_final['DJ_Ajclose']\n\ndf_p = pd.DataFrame({'GLD':GLD_adj_close, 'SPY':SPY_adj_close, 'DJ':DJ_adj_close})\n\ndf_ax = df_p.plot(title='Effect of Index prices on gold rates',figsize=(15,8))\n\ndf_ax.set_ylabel('Price')\ndf_ax.legend(loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:21.537941Z","iopub.execute_input":"2021-07-20T15:08:21.538274Z","iopub.status.idle":"2021-07-20T15:08:21.781789Z","shell.execute_reply.started":"2021-07-20T15:08:21.538244Z","shell.execute_reply":"2021-07-20T15:08:21.780988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Computing Daily Returns of all Features","metadata":{}},{"cell_type":"code","source":"def compute_daily_returns(df):\n    \"\"\"Compute and return the daily return values.\"\"\"\n    # TODO: Your code here\n    # Note: Returned DataFrame must have the same number of rows\n    daily_return = (df / df.shift(1)) - 1\n    daily_return[0] = 0\n    return daily_return\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:23.958833Z","iopub.execute_input":"2021-07-20T15:08:23.95922Z","iopub.status.idle":"2021-07-20T15:08:23.96435Z","shell.execute_reply.started":"2021-07-20T15:08:23.959174Z","shell.execute_reply":"2021-07-20T15:08:23.963216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GLD_adj_close = df_final['Adj Close']\nSPY_adj_close = df_final['SP_Ajclose']\nDJ_adj_close  = df_final['DJ_Ajclose']\nEG_adj_close =  df_final['EG_Ajclose']\nUSO_Adj_close = df_final['USO_Adj Close']\nGDX_Adj_close = df_final['GDX_Adj Close']\nEU_price      = df_final['EU_Price']\nOF_price      = df_final['OF_Price']\nOS_price      = df_final['OS_Price']\nSF_price      = df_final['SF_Price']\nUSB_price      = df_final['USB_Price']\nPLT_price      = df_final['PLT_Price']\nPLD_price      = df_final['PLD_Price']\nrho_price      = df_final['RHO_PRICE']\nusdi_price      = df_final['USDI_Price']\n\n\n\nGLD_daily_return = compute_daily_returns(GLD_adj_close)\nSPY_daily_return = compute_daily_returns(SPY_adj_close)\nDJ_adj_return    = compute_daily_returns(DJ_adj_close)\nEG_adj_return     = compute_daily_returns(EG_adj_close)\nUSO_Adj_return    = compute_daily_returns(USO_Adj_close)\nGDX_Adj_return   =compute_daily_returns(GDX_Adj_close)\nEU_return        = compute_daily_returns(EU_price)\nOF_price         =compute_daily_returns(OF_price)\nOS_price         =compute_daily_returns(OS_price)\nSF_price         =compute_daily_returns(SF_price)\nUSB_price         =compute_daily_returns(USB_price)\nPLT_price         =compute_daily_returns(PLT_price)\nPLD_price         =compute_daily_returns(PLD_price)\nrho_price         =compute_daily_returns(rho_price)\nUSDI_price         =compute_daily_returns(usdi_price)\n\ndf_d = pd.DataFrame({'GLD':GLD_daily_return, 'SPY':SPY_daily_return, 'DJ':DJ_adj_return, 'EG':EG_adj_return, 'USO':USO_Adj_return,\n                  'GDX':GDX_Adj_return,'EU':EU_return, 'OF':OF_price,'SF':SF_price,'OS':OS_price, 'USB':USB_price, 'PLT':PLT_price, 'PLD':PLD_price,\n                  'RHO':rho_price,'USDI':USDI_price})\n\ndaily_ax = df_d[-100:].plot(title='Last 100 records of daily return of all features',figsize=(15,8))\n\ndaily_ax.set_ylabel('Daily return')\ndaily_ax.legend(loc='lower left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:24.678105Z","iopub.execute_input":"2021-07-20T15:08:24.678495Z","iopub.status.idle":"2021-07-20T15:08:25.112594Z","shell.execute_reply.started":"2021-07-20T15:08:24.678463Z","shell.execute_reply":"2021-07-20T15:08:25.111686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Computing daily returns of stock indexes","metadata":{}},{"cell_type":"code","source":"df_s = pd.DataFrame({'GLD':GLD_daily_return, 'SPY':SPY_daily_return, 'DJ':DJ_adj_return})\n\ndaily_ax = df_s[-100:].plot(title='Last 100 records of daily return of Stock Indexes',figsize=(15,8))\n\ndaily_ax.set_ylabel('Daily return')\ndaily_ax.legend(loc='lower left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:27.659106Z","iopub.execute_input":"2021-07-20T15:08:27.659441Z","iopub.status.idle":"2021-07-20T15:08:27.861567Z","shell.execute_reply.started":"2021-07-20T15:08:27.659415Z","shell.execute_reply":"2021-07-20T15:08:27.860701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scatterplot","metadata":{}},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='SPY', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:30.150296Z","iopub.execute_input":"2021-07-20T15:08:30.150603Z","iopub.status.idle":"2021-07-20T15:08:30.329605Z","shell.execute_reply.started":"2021-07-20T15:08:30.150579Z","shell.execute_reply":"2021-07-20T15:08:30.327774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='DJ', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:31.199398Z","iopub.execute_input":"2021-07-20T15:08:31.199705Z","iopub.status.idle":"2021-07-20T15:08:31.360937Z","shell.execute_reply.started":"2021-07-20T15:08:31.19968Z","shell.execute_reply":"2021-07-20T15:08:31.360181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='EG', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:31.759417Z","iopub.execute_input":"2021-07-20T15:08:31.759779Z","iopub.status.idle":"2021-07-20T15:08:31.964936Z","shell.execute_reply.started":"2021-07-20T15:08:31.759744Z","shell.execute_reply":"2021-07-20T15:08:31.963608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='USO', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:32.255883Z","iopub.execute_input":"2021-07-20T15:08:32.256346Z","iopub.status.idle":"2021-07-20T15:08:32.453144Z","shell.execute_reply.started":"2021-07-20T15:08:32.256308Z","shell.execute_reply":"2021-07-20T15:08:32.452292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='USB', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:32.739502Z","iopub.execute_input":"2021-07-20T15:08:32.739794Z","iopub.status.idle":"2021-07-20T15:08:32.905471Z","shell.execute_reply.started":"2021-07-20T15:08:32.739768Z","shell.execute_reply":"2021-07-20T15:08:32.904464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='EU', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:33.247996Z","iopub.execute_input":"2021-07-20T15:08:33.248465Z","iopub.status.idle":"2021-07-20T15:08:33.410968Z","shell.execute_reply.started":"2021-07-20T15:08:33.248437Z","shell.execute_reply":"2021-07-20T15:08:33.410331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='PLT', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:33.809179Z","iopub.execute_input":"2021-07-20T15:08:33.809633Z","iopub.status.idle":"2021-07-20T15:08:33.977315Z","shell.execute_reply.started":"2021-07-20T15:08:33.809607Z","shell.execute_reply":"2021-07-20T15:08:33.976479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d.plot(kind='scatter', x='PLD', y='GLD')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:34.269908Z","iopub.execute_input":"2021-07-20T15:08:34.270231Z","iopub.status.idle":"2021-07-20T15:08:34.449743Z","shell.execute_reply.started":"2021-07-20T15:08:34.270205Z","shell.execute_reply":"2021-07-20T15:08:34.448849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Statistical Measures (Mean, Standard deviation, Kurtosis)","metadata":{}},{"cell_type":"markdown","source":"**Kurtosis** is a statistical measure that is used to describe the distribution. Whereas skewness differentiates extreme values in one versus the other tail, kurtosis measures extreme values in either tail. Distributions with large kurtosis exhibit tail data exceeding the tails of the normal distribution (e.g., five or more standard deviations from the mean). Distributions with low kurtosis exhibit tail data that is generally less extreme than the tails of the normal distribution.\n\n\nFor investors, high kurtosis of the return distribution implies that the investor will experience occasional extreme returns (either positive or negative), more extreme than the usual + or - three standard deviations from the mean that is predicted by the normal distribution of returns. This phenomenon is known as **kurtosis risk**.\n\n**Positive Kurtosis**\nMore weights in the tail\n\n![Positive](pos.png)\n\n**Negative Kurtosis**\nIt has as much data in each tail as it does in the peak.\n\n![Negative](neg.png)","metadata":{}},{"cell_type":"code","source":"# computing mean,standard deviation and kurtosis of Gold ETF daily return\n\nmean=df_d['GLD'].mean()\n# computing standard deviation of Gold stock\nstd=df_d['GLD'].std()\nkurt=df_d['GLD'].kurtosis()\nprint('Mean=',mean)\nprint('Standard Deviation=',std)\nprint('Kurtosis=',kurt)\n#Plotting Histogram\ndf_d['GLD'].hist(bins=20)\n\nplt.axvline(mean, color='w',linestyle='dashed',linewidth=2)\nplt.axvline(std, color='r',linestyle='dashed',linewidth=2)\nplt.axvline(-std, color='r',linestyle='dashed',linewidth=2)\nplt.title(\"Plotting of Mean, Standard deviation and Kurtosis of Gold Prices\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:36.082788Z","iopub.execute_input":"2021-07-20T15:08:36.083096Z","iopub.status.idle":"2021-07-20T15:08:36.339593Z","shell.execute_reply.started":"2021-07-20T15:08:36.083071Z","shell.execute_reply":"2021-07-20T15:08:36.339015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# computing mean,standard deviation and kurtosis of S&P 500 Index daily return\n\nmean=df_d['SPY'].mean()\n# computing standard deviation of Gold stock\nstd=df_d['SPY'].std()\nkurt=df_d['SPY'].kurtosis()\nprint('Mean=',mean)\nprint('Standard Deviation=',std)\nprint('Kurtosis=',kurt)\n#Plotting Histogram\ndf_d['SPY'].hist(bins=20)\n\nplt.axvline(mean, color='w',linestyle='dashed',linewidth=2)\nplt.axvline(std, color='r',linestyle='dashed',linewidth=2)\nplt.axvline(-std, color='r',linestyle='dashed',linewidth=2)\nplt.title(\"Plotting of Mean, Standard deviation and Kurtosis of SPY Prices\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:36.919545Z","iopub.execute_input":"2021-07-20T15:08:36.92009Z","iopub.status.idle":"2021-07-20T15:08:37.133572Z","shell.execute_reply.started":"2021-07-20T15:08:36.920055Z","shell.execute_reply":"2021-07-20T15:08:37.132995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# computing mean,standard deviation and kurtosis of Dow Jones Index daily return\nmean=df_d['DJ'].mean()\n# computing standard deviation of Gold stock\nstd=df_d['DJ'].std()\nkurt=df_d['DJ'].kurtosis()\nprint('Mean=',mean)\nprint('Standard Deviation=',std)\nprint('Kurtosis=',kurt)\n#Plotting Histogram\ndf_d['DJ'].hist(bins=20)\n\nplt.axvline(mean, color='w',linestyle='dashed',linewidth=2)\nplt.axvline(std, color='r',linestyle='dashed',linewidth=2)\nplt.axvline(-std, color='r',linestyle='dashed',linewidth=2)\nplt.title(\"Plotting of Mean, Standard deviation and Kurtosis of Dow jones Prices\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:37.639247Z","iopub.execute_input":"2021-07-20T15:08:37.639863Z","iopub.status.idle":"2021-07-20T15:08:37.852638Z","shell.execute_reply.started":"2021-07-20T15:08:37.639811Z","shell.execute_reply":"2021-07-20T15:08:37.851879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation Analysis","metadata":{}},{"cell_type":"markdown","source":"### Plotting Correlation Matrix","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(24,18)) \nsns.heatmap(df_final.corr(), annot=True) ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:08:39.291457Z","iopub.execute_input":"2021-07-20T15:08:39.291835Z","iopub.status.idle":"2021-07-20T15:09:08.539296Z","shell.execute_reply.started":"2021-07-20T15:08:39.291801Z","shell.execute_reply":"2021-07-20T15:09:08.538374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df_final.drop(['Adj Close'],axis=1)\nX=X.drop(['Close'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:13.751842Z","iopub.execute_input":"2021-07-20T15:09:13.752358Z","iopub.status.idle":"2021-07-20T15:09:13.758412Z","shell.execute_reply.started":"2021-07-20T15:09:13.752316Z","shell.execute_reply":"2021-07-20T15:09:13.757724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.corrwith(df_final['Adj Close']).plot.bar(\n        figsize = (20, 10), title = \"Correlation with Adj Close\", fontsize = 20,\n        rot = 90, grid = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:14.801995Z","iopub.execute_input":"2021-07-20T15:09:14.802355Z","iopub.status.idle":"2021-07-20T15:09:16.19957Z","shell.execute_reply.started":"2021-07-20T15:09:14.802324Z","shell.execute_reply":"2021-07-20T15:09:16.198911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix=df_final.corr()\ncoef=corr_matrix[\"Adj Close\"].sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:22.478307Z","iopub.execute_input":"2021-07-20T15:09:22.47876Z","iopub.status.idle":"2021-07-20T15:09:22.526306Z","shell.execute_reply.started":"2021-07-20T15:09:22.478722Z","shell.execute_reply":"2021-07-20T15:09:22.52524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Positively Correlated Variables","metadata":{}},{"cell_type":"code","source":"pos_corr=coef[coef>0]\npos_corr","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:24.110565Z","iopub.execute_input":"2021-07-20T15:09:24.11111Z","iopub.status.idle":"2021-07-20T15:09:24.119559Z","shell.execute_reply.started":"2021-07-20T15:09:24.111063Z","shell.execute_reply":"2021-07-20T15:09:24.118991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Negatively Correlated Variables","metadata":{}},{"cell_type":"code","source":"neg_corr=coef[coef<0]\nneg_corr","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:29.722821Z","iopub.execute_input":"2021-07-20T15:09:29.72334Z","iopub.status.idle":"2021-07-20T15:09:29.730555Z","shell.execute_reply.started":"2021-07-20T15:09:29.72331Z","shell.execute_reply":"2021-07-20T15:09:29.729899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Technical Indicators","metadata":{}},{"cell_type":"markdown","source":"I will also use following technical indicators which I feel help as a feature for prediction of Gold price\n\n**1. MACD :** The moving average convergence-divergence (MACD) is one of the most powerful and well-known indicators in technical analysis. The indicator is comprised of two exponential moving averages that help measure momentum in a security. The MACD is simply the difference between these two moving averages plotted against a centerline, where the centerline is the point at which the two moving averages are equal.\n\n**2. RSI :** The relative strength index (RSI) is another well known momentum indicators thatâ€™s widely used in technical analysis. The indicator is commonly used to identify overbought and oversold conditions in a security with a range between 0 (oversold) and 100 (overbought).\n\n**3. Simple Moving Average (SMA) :** simply takes the sum of all of the past closing prices over a time period and divides the result by the total number of prices used in the calculation. For example, a 10-day simple moving average takes the last ten closing prices and divides them by ten.\n\n**4. Upper Band**\n\n**5. Lower Band**\n\n**6. DIFF**\n\n**7. Open-Close**\n\n**8. High-Low**","metadata":{}},{"cell_type":"code","source":"def calculate_MACD(df, nslow=26, nfast=12):\n    emaslow = df.ewm(span=nslow, min_periods=nslow, adjust=True, ignore_na=False).mean()\n    emafast = df.ewm(span=nfast, min_periods=nfast, adjust=True, ignore_na=False).mean()\n    dif = emafast - emaslow\n    MACD = dif.ewm(span=9, min_periods=9, adjust=True, ignore_na=False).mean()\n    return dif, MACD\n\ndef calculate_RSI(df, periods=14):\n    # wilder's RSI\n    delta = df.diff()\n    up, down = delta.copy(), delta.copy()\n\n    up[up < 0] = 0\n    down[down > 0] = 0\n\n    rUp = up.ewm(com=periods,adjust=False).mean()\n    rDown = down.ewm(com=periods, adjust=False).mean().abs()\n\n    rsi = 100 - 100 / (1 + rUp / rDown)\n    return rsi\n\ndef calculate_SMA(df, peroids=15):\n    SMA = df.rolling(window=peroids, min_periods=peroids, center=False).mean()\n    return SMA\n\ndef calculate_BB(df, peroids=15):\n    STD = df.rolling(window=peroids,min_periods=peroids, center=False).std()\n    SMA = calculate_SMA(df)\n    upper_band = SMA + (2 * STD)\n    lower_band = SMA - (2 * STD)\n    return upper_band, lower_band\n\ndef calculate_stdev(df,periods=5):\n    STDEV = df.rolling(periods).std()\n    return STDEV","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:40.845992Z","iopub.execute_input":"2021-07-20T15:09:40.846512Z","iopub.status.idle":"2021-07-20T15:09:40.857684Z","shell.execute_reply.started":"2021-07-20T15:09:40.84647Z","shell.execute_reply":"2021-07-20T15:09:40.856992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Technical Indicators","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n\n# Calculate Simple Moving Average for GLD\nSMA_GLD = calculate_SMA(GLD_adj_close)\n\nGLD_adj_close[:365].plot(title='GLD Moving Average',label='GLD', ax=axes[0])\n\nSMA_GLD[:365].plot(label=\"SMA\",ax=axes[0])\n\n\n# Calculate Bollinger Bands for GLD\nupper_band, lower_band = calculate_BB(GLD_adj_close)\n\nupper_band[:365].plot(label='upper band', ax=axes[0])\nlower_band[:365].plot(label='lower band', ax=axes[0])\n\n\n# Calculate MACD for GLD\nDIF, MACD = calculate_MACD(GLD_adj_close)\n\nDIF[:365].plot(title='DIF and MACD',label='DIF', ax=axes[1])\nMACD[:365].plot(label='MACD', ax=axes[1])\n\n# Calculate RSI for GLD\nRSI = calculate_RSI(GLD_adj_close)\nRSI[:365].plot(title='RSI',label='RSI', ax=axes[2])\n\n# Calculating Standard deviation for GLD\nSTDEV= calculate_stdev(GLD_adj_close)\nSTDEV[:365].plot(title='STDEV',label='STDEV', ax=axes[3])\n\nOpen_Close=df_final.Open - df_final.Close\n\nHigh_Low=df_final.High-df_final.Low\n\naxes[0].set_ylabel('Price')\naxes[1].set_ylabel('Price')\naxes[2].set_ylabel('Price')\naxes[3].set_ylabel('Price')\n\n\n\naxes[0].legend(loc='lower left')\naxes[1].legend(loc='lower left')\naxes[2].legend(loc='lower left')\naxes[3].legend(loc='lower left')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:41.882956Z","iopub.execute_input":"2021-07-20T15:09:41.883454Z","iopub.status.idle":"2021-07-20T15:09:42.774971Z","shell.execute_reply.started":"2021-07-20T15:09:41.883413Z","shell.execute_reply":"2021-07-20T15:09:42.774149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\nOpen_Close=df_final.Open - df_final.Close\nOpen_Close[:365].plot(title='Open-close',label='Open_Close', ax=axes[0])\n\nHigh_Low=df_final.High-df_final.Low\nHigh_Low[:365].plot(title='High_Low',label='High_Low', ax=axes[1])\naxes[0].set_ylabel('Price')\naxes[1].set_ylabel('Price')\n\n\n\n\naxes[0].legend(loc='lower left')\naxes[1].legend(loc='lower left')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:42.935636Z","iopub.execute_input":"2021-07-20T15:09:42.935924Z","iopub.status.idle":"2021-07-20T15:09:43.386711Z","shell.execute_reply.started":"2021-07-20T15:09:42.935898Z","shell.execute_reply":"2021-07-20T15:09:43.385863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = df_final\ntest['SMA'] = SMA_GLD\ntest['Upper_band'] = upper_band\ntest['Lower_band'] = lower_band\ntest['DIF'] = DIF\ntest['MACD'] = MACD\ntest['RSI'] = RSI\ntest['STDEV'] = STDEV\ntest['Open_Close']=Open_Close\ntest['High_Low']=High_Low\n\n\n# Dropping first 33 records from the data as it has null values because of introduction of technical indicators\ntest = test[33:]\n\n# Target column\ntarget_adj_close = pd.DataFrame(test['Adj Close'])\n\n\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:43.812768Z","iopub.execute_input":"2021-07-20T15:09:43.813088Z","iopub.status.idle":"2021-07-20T15:09:43.850772Z","shell.execute_reply.started":"2021-07-20T15:09:43.813062Z","shell.execute_reply":"2021-07-20T15:09:43.849945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:44.552558Z","iopub.execute_input":"2021-07-20T15:09:44.552918Z","iopub.status.idle":"2021-07-20T15:09:44.559843Z","shell.execute_reply.started":"2021-07-20T15:09:44.55289Z","shell.execute_reply":"2021-07-20T15:09:44.558821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this step I would segregate feature and target variables. I will not use Close feature of GLD ETF and will use Adjusted Close of Gold ETF as target variable ","metadata":{}},{"cell_type":"code","source":"# selecting Feature Columns\nfeature_columns = ['Open', 'High', 'Low', 'Volume','SP_open','SP_high','SP_low','SP_Ajclose','SP_volume','DJ_open','DJ_high', 'DJ_low',  'DJ_Ajclose', 'DJ_volume', 'EG_open','EG_high', 'EG_low',  \n                   'EG_Ajclose', 'EG_volume', 'EU_Price','EU_open', 'EU_high', 'EU_low', 'EU_Trend', 'OF_Price','OF_Open','OF_High', 'OF_Low', 'OF_Volume', 'OF_Trend', 'OS_Price', 'OS_Open','OS_High', 'OS_Low', 'OS_Trend', 'SF_Price', 'SF_Open', 'SF_High',\n                   'SF_Low', 'SF_Volume', 'SF_Trend', 'USB_Price', 'USB_Open', 'USB_High','USB_Low', 'USB_Trend', 'PLT_Price', 'PLT_Open', 'PLT_High', 'PLT_Low',\n                    'PLT_Trend', 'PLD_Price', 'PLD_Open', 'PLD_High', 'PLD_Low','PLD_Trend', 'RHO_PRICE', 'USDI_Price', 'USDI_Open', 'USDI_High',\n                     'USDI_Low', 'USDI_Volume', 'USDI_Trend','GDX_Open', 'GDX_High',\n       'GDX_Low', 'GDX_Close', 'GDX_Adj Close', 'GDX_Volume', 'USO_Open',\n       'USO_High', 'USO_Low', 'USO_Close', 'USO_Adj Close', 'USO_Volume','SMA', 'Upper_band', 'Lower_band', 'DIF', 'MACD','RSI','STDEV','Open_Close', 'High_Low']\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:45.767433Z","iopub.execute_input":"2021-07-20T15:09:45.767758Z","iopub.status.idle":"2021-07-20T15:09:45.777013Z","shell.execute_reply.started":"2021-07-20T15:09:45.767727Z","shell.execute_reply":"2021-07-20T15:09:45.776008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalizing the data\n\nIn this step I would perform feature scaling/normalization of feature variables using sklearn's MinMaxScaler function.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfeature_minmax_transform_data = scaler.fit_transform(test[feature_columns])\nfeature_minmax_transform = pd.DataFrame(columns=feature_columns, data=feature_minmax_transform_data, index=test.index)\nfeature_minmax_transform.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:46.809027Z","iopub.execute_input":"2021-07-20T15:09:46.809393Z","iopub.status.idle":"2021-07-20T15:09:46.851046Z","shell.execute_reply.started":"2021-07-20T15:09:46.809362Z","shell.execute_reply":"2021-07-20T15:09:46.85027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(feature_minmax_transform.head())\nprint('Shape of features : ', feature_minmax_transform.shape)\nprint('Shape of target : ', target_adj_close.shape)\n\n# Shift target array because we want to predict the n + 1 day value\n\n\ntarget_adj_close = target_adj_close.shift(-1)\nvalidation_y = target_adj_close[-90:-1]\ntarget_adj_close = target_adj_close[:-90]\n\n# Taking last 90 rows of data to be validation set\nvalidation_X = feature_minmax_transform[-90:-1]\nfeature_minmax_transform = feature_minmax_transform[:-90]\ndisplay(validation_X.tail())\ndisplay(validation_y.tail())\n\nprint(\"\\n -----After process------ \\n\")\nprint('Shape of features : ', feature_minmax_transform.shape)\nprint('Shape of target : ', target_adj_close.shape)\ndisplay(target_adj_close.tail())","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:47.258984Z","iopub.execute_input":"2021-07-20T15:09:47.259426Z","iopub.status.idle":"2021-07-20T15:09:47.327367Z","shell.execute_reply.started":"2021-07-20T15:09:47.259389Z","shell.execute_reply":"2021-07-20T15:09:47.326518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split\n\nIn this step we would perform Train test split using sklearn's Timeseries split","metadata":{}},{"cell_type":"code","source":"ts_split= TimeSeriesSplit(n_splits=10)\nfor train_index, test_index in ts_split.split(feature_minmax_transform):\n        X_train, X_test = feature_minmax_transform[:len(train_index)], feature_minmax_transform[len(train_index): (len(train_index)+len(test_index))]\n        y_train, y_test = target_adj_close[:len(train_index)].values.ravel(), target_adj_close[len(train_index): (len(train_index)+len(test_index))].values.ravel()\n       ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:48.200018Z","iopub.execute_input":"2021-07-20T15:09:48.200398Z","iopub.status.idle":"2021-07-20T15:09:48.210632Z","shell.execute_reply.started":"2021-07-20T15:09:48.200366Z","shell.execute_reply":"2021-07-20T15:09:48.209565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:48.788189Z","iopub.execute_input":"2021-07-20T15:09:48.788559Z","iopub.status.idle":"2021-07-20T15:09:48.794696Z","shell.execute_reply.started":"2021-07-20T15:09:48.788525Z","shell.execute_reply":"2021-07-20T15:09:48.793681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:49.287105Z","iopub.execute_input":"2021-07-20T15:09:49.287508Z","iopub.status.idle":"2021-07-20T15:09:49.293251Z","shell.execute_reply.started":"2021-07-20T15:09:49.287474Z","shell.execute_reply":"2021-07-20T15:09:49.292225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:49.779963Z","iopub.execute_input":"2021-07-20T15:09:49.780313Z","iopub.status.idle":"2021-07-20T15:09:49.785738Z","shell.execute_reply.started":"2021-07-20T15:09:49.780284Z","shell.execute_reply":"2021-07-20T15:09:49.784922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:50.297998Z","iopub.execute_input":"2021-07-20T15:09:50.298333Z","iopub.status.idle":"2021-07-20T15:09:50.303603Z","shell.execute_reply.started":"2021-07-20T15:09:50.298305Z","shell.execute_reply":"2021-07-20T15:09:50.303025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate_result(model, model_name):\n    predicted = model.predict(validation_X)\n    RSME_score = np.sqrt(mean_squared_error(validation_y, predicted))\n    print('RMSE: ', RSME_score)\n    \n    R2_score = r2_score(validation_y, predicted)\n    print('R2 score: ', R2_score)\n\n    plt.plot(validation_y.index, predicted,'r', label='Predict')\n    plt.plot(validation_y.index, validation_y,'b', label='Actual')\n    plt.ylabel('Price')\n    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n    plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n    plt.title(model_name + ' Predict vs Actual')\n    plt.legend(loc='upper right')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:50.689198Z","iopub.execute_input":"2021-07-20T15:09:50.689541Z","iopub.status.idle":"2021-07-20T15:09:50.695984Z","shell.execute_reply.started":"2021-07-20T15:09:50.689514Z","shell.execute_reply":"2021-07-20T15:09:50.69532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building\n\n### 1. Benchmark Model :\n       I will use Decision Tree Regressor with default parameter as my Benchmark model for the project.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndt = DecisionTreeRegressor(random_state=0)\n\nbenchmark_dt=dt.fit(X_train, y_train)\n\nvalidate_result(benchmark_dt, 'Decision Tree Regression')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:51.824013Z","iopub.execute_input":"2021-07-20T15:09:51.824502Z","iopub.status.idle":"2021-07-20T15:09:52.093406Z","shell.execute_reply.started":"2021-07-20T15:09:51.824471Z","shell.execute_reply":"2021-07-20T15:09:52.092293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Solution Model \n\n### Support Vector Regressor (SVR)","metadata":{}},{"cell_type":"code","source":"# Save all soultion models\nsolution_models = {}\n# SVR with  linear Kernel\nsvr_lin = SVR(kernel='linear')\nlinear_svr_clf_feat = svr_lin.fit(X_train,y_train)\nvalidate_result(linear_svr_clf_feat,'Linear SVR All Feat')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:53.375999Z","iopub.execute_input":"2021-07-20T15:09:53.376356Z","iopub.status.idle":"2021-07-20T15:09:53.867048Z","shell.execute_reply.started":"2021-07-20T15:09:53.37633Z","shell.execute_reply":"2021-07-20T15:09:53.866099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter Tuning\nIn this step I will tune two parameters of SVR C and epsilon to see if the model shows any improvement.","metadata":{}},{"cell_type":"code","source":"linear_svr_parameters = {\n    'C':[0.5, 1.0, 10.0, 50.0],\n    'epsilon':[0, 0.1, 0.5, 0.7, 0.9],\n}\n\nlsvr_grid_search_feat = GridSearchCV(estimator=linear_svr_clf_feat,\n                           param_grid=linear_svr_parameters,\n                           cv=ts_split,\n)\n\nlsvr_grid_search_feat.fit(X_train, y_train)\n\nvalidate_result(lsvr_grid_search_feat,'Linear SVR GS All Feat')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:09:54.434199Z","iopub.execute_input":"2021-07-20T15:09:54.434568Z","iopub.status.idle":"2021-07-20T15:10:58.457661Z","shell.execute_reply.started":"2021-07-20T15:09:54.434539Z","shell.execute_reply":"2021-07-20T15:10:58.456595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we have seen using gridsearch on SVR we get significant improvement in R2 score and RMSE also came down so we will save this as our first solution model ","metadata":{}},{"cell_type":"code","source":"\nsolution_models['SVR All Feat'] = lsvr_grid_search_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:10:58.459033Z","iopub.execute_input":"2021-07-20T15:10:58.459328Z","iopub.status.idle":"2021-07-20T15:10:58.463374Z","shell.execute_reply.started":"2021-07-20T15:10:58.459303Z","shell.execute_reply":"2021-07-20T15:10:58.462501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Solution Model : Random Forest","metadata":{}},{"cell_type":"code","source":"rf_cl = RandomForestRegressor(n_estimators=50, random_state=0)\nrandom_forest_clf_feat = rf_cl.fit(X_train,y_train)\nvalidate_result(random_forest_clf_feat,'Random Forest with All feat')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:10:58.464847Z","iopub.execute_input":"2021-07-20T15:10:58.465092Z","iopub.status.idle":"2021-07-20T15:11:01.888005Z","shell.execute_reply.started":"2021-07-20T15:10:58.465069Z","shell.execute_reply":"2021-07-20T15:11:01.887089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyper parameter Tuning\nIn this I will tune 3 parameters of Random forest which are n_estimators,max_features,max_depth","metadata":{}},{"cell_type":"code","source":"random_forest_parameters = {\n    'n_estimators':[10,15,20, 50, 100],\n    'max_features':['auto','sqrt','log2'],\n    'max_depth':[2, 3, 5, 7,10],\n}\n\ngrid_search_RF_feat = GridSearchCV(estimator=random_forest_clf_feat,\n                           param_grid=random_forest_parameters,\n                           cv=ts_split,\n)\n\ngrid_search_RF_feat.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:11:14.837283Z","iopub.execute_input":"2021-07-20T15:11:14.837619Z","iopub.status.idle":"2021-07-20T15:14:38.56642Z","shell.execute_reply.started":"2021-07-20T15:11:14.837591Z","shell.execute_reply":"2021-07-20T15:14:38.565549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(grid_search_RF_feat.best_params_)\nvalidate_result(grid_search_RF_feat,'RandomForest GS')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:14:50.509398Z","iopub.execute_input":"2021-07-20T15:14:50.509768Z","iopub.status.idle":"2021-07-20T15:14:50.675596Z","shell.execute_reply.started":"2021-07-20T15:14:50.50974Z","shell.execute_reply":"2021-07-20T15:14:50.674569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we have seen, Random forest with default parameters performed better than tuned Random forest model.So, we will include random forest with default parameters as our second solution model.","metadata":{}},{"cell_type":"code","source":"solution_models['Random_Forest with Feat'] = random_forest_clf_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:15:15.277045Z","iopub.execute_input":"2021-07-20T15:15:15.277371Z","iopub.status.idle":"2021-07-20T15:15:15.280474Z","shell.execute_reply.started":"2021-07-20T15:15:15.277345Z","shell.execute_reply":"2021-07-20T15:15:15.279761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Solution Model : Lasso and Ridge","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV\n\nlasso_clf = LassoCV(n_alphas=1000, max_iter=3000, random_state=0)\nridge_clf = RidgeCV(gcv_mode='auto')\n\nlasso_clf_feat = lasso_clf.fit(X_train,y_train)\nvalidate_result(lasso_clf_feat,'LassoCV')\nsolution_models['LassoCV All feat'] = lasso_clf_feat\n\nridge_clf_feat = ridge_clf.fit(X_train,y_train)\nvalidate_result(ridge_clf_feat,'RidgeCV')\nsolution_models['RidgeCV All Feat'] = ridge_clf_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:15:18.885886Z","iopub.execute_input":"2021-07-20T15:15:18.886345Z","iopub.status.idle":"2021-07-20T15:15:20.467303Z","shell.execute_reply.started":"2021-07-20T15:15:18.886315Z","shell.execute_reply":"2021-07-20T15:15:20.46644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Solution Model : Bayesian Ridge","metadata":{}},{"cell_type":"code","source":"from sklearn import linear_model\nbay = linear_model.BayesianRidge()\nbay_feat = bay.fit(X_train,y_train)\nvalidate_result(bay_feat,'Bayesian')\nsolution_models['Bay All Feat'] = bay_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:15:25.02065Z","iopub.execute_input":"2021-07-20T15:15:25.021015Z","iopub.status.idle":"2021-07-20T15:15:25.248715Z","shell.execute_reply.started":"2021-07-20T15:15:25.020985Z","shell.execute_reply":"2021-07-20T15:15:25.247176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Solution Model : Gradient Boosting Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nregr =GradientBoostingRegressor(n_estimators=70, learning_rate=0.1,max_depth=4, random_state=0, loss='ls')\nGB_feat = regr.fit(X_train,y_train)\nvalidate_result(GB_feat,'NB')\nsolution_models['GB All Feat'] = GB_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:15:29.424335Z","iopub.execute_input":"2021-07-20T15:15:29.424644Z","iopub.status.idle":"2021-07-20T15:15:32.13698Z","shell.execute_reply.started":"2021-07-20T15:15:29.424612Z","shell.execute_reply":"2021-07-20T15:15:32.136272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Solution Model : Stochastic Gradient Descent (SGD)","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor\nsgd =SGDRegressor(max_iter=1000, tol=1e-3,loss='squared_epsilon_insensitive',penalty='l1',alpha=0.1)\nsgd_feat = sgd.fit(X_train,y_train)\nvalidate_result(sgd_feat,'SGD')\nsolution_models['SGD All Feat'] = sgd_feat","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:15:36.256949Z","iopub.execute_input":"2021-07-20T15:15:36.257381Z","iopub.status.idle":"2021-07-20T15:15:36.800574Z","shell.execute_reply.started":"2021-07-20T15:15:36.257352Z","shell.execute_reply":"2021-07-20T15:15:36.799652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Review\nIn this step, we will review benchmark model and all the solution model based on evaluation metrics i.e, RMSE and R2 score","metadata":{}},{"cell_type":"code","source":"RMSE_scores = {}\ndef model_review(models):\n    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(16, 16))\n\n    #plot benchmark model\n    benchmark_predicted = benchmark_dt.predict(validation_X)\n    benchmark_RSME_score = np.sqrt(mean_squared_error(validation_y, benchmark_predicted))\n    RMSE_scores['Benchmark'] = benchmark_RSME_score\n    \n    axes[0,0].plot(validation_y.index, benchmark_predicted,'r', label='Predict')\n    axes[0,0].plot(validation_y.index, validation_y,'b', label='Actual')\n    axes[0,0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    axes[0,0].xaxis.set_major_locator(mdates.MonthLocator())\n    axes[0,0].set_ylabel('Price')\n    axes[0,0].set_title(\"Benchmark Predict's RMSE Error: \" +\"{0:.2f}\".format(benchmark_RSME_score))\n    axes[0,0].legend(loc='upper right')\n    \n    #plot block\n    ax_x = 0\n    ax_y = 1\n    #plot solution model\n    for name, model in models.items():\n        predicted = model.predict(validation_X)\n        RSME_score = np.sqrt(mean_squared_error(validation_y, predicted))\n\n           \n        axes[ax_x][ax_y].plot(validation_y.index, predicted,'r', label='Predict')\n        axes[ax_x][ax_y].plot(validation_y.index, validation_y,'b', label='Actual')\n        axes[ax_x][ax_y].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n        axes[ax_x][ax_y].xaxis.set_major_locator(mdates.MonthLocator())\n        axes[ax_x][ax_y].set_ylabel('Price')\n        axes[ax_x][ax_y].set_title(name + \"'s RMSE Error: \" +\"{0:.2f}\".format(RSME_score))\n        axes[ax_x][ax_y].legend(loc='upper right')\n        RMSE_scores[name] = RSME_score\n        if ax_x <=2:\n            if ax_y < 2:\n                ax_y += 1\n            else:\n                ax_x += 1\n                ax_y = 0\n    plt.show()\n\nmodel_review(solution_models)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:15:43.231492Z","iopub.execute_input":"2021-07-20T15:15:43.231858Z","iopub.status.idle":"2021-07-20T15:15:44.369879Z","shell.execute_reply.started":"2021-07-20T15:15:43.231829Z","shell.execute_reply":"2021-07-20T15:15:44.369021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparison of RMSE of Benchmark and all Solution Models","metadata":{}},{"cell_type":"code","source":"\nmodel_names = []\nmodel_values = []\nfor name, value in RMSE_scores.items():\n    model_names.append(name)\n    model_values.append(value)\n\nmodel_values = np.array(model_values)\nmodel_names = np.array(model_names)\n\nindices = np.argsort(model_values)\ncolumns = model_names[indices[:8]]\nvalues = model_values[indices][:8]\n\nfig = plt.figure(figsize = (16,8))\nplt.bar(np.arange(8), values ,width = 0.6, align=\"center\", color = '#ff00c1')\nplt.xticks(np.arange(8), columns)\nplt.xlabel('Model')\nplt.ylabel('RMSE')\nplt.title('RMSE compare')   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:15:50.853724Z","iopub.execute_input":"2021-07-20T15:15:50.8541Z","iopub.status.idle":"2021-07-20T15:15:51.022335Z","shell.execute_reply.started":"2021-07-20T15:15:50.854071Z","shell.execute_reply":"2021-07-20T15:15:51.021705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection\n\nIn this step we will select supporting features using sklearn's **SelectFromModel** library using Lasso regressor as it has lowest RMSE.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nsfm = SelectFromModel(lasso_clf_feat)\nsfm.fit(feature_minmax_transform, target_adj_close.values.ravel())\ndisplay(feature_minmax_transform.head())\nsup = sfm.get_support()\nzipped = zip(feature_minmax_transform,sup)\nprint(*zipped)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:16:02.405608Z","iopub.execute_input":"2021-07-20T15:16:02.406149Z","iopub.status.idle":"2021-07-20T15:16:03.659321Z","shell.execute_reply.started":"2021-07-20T15:16:02.406099Z","shell.execute_reply":"2021-07-20T15:16:03.65544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting Features which supports Model building process\n\nfeature_selected = feature_minmax_transform[['Open','High','Low','OF_Trend','USB_Trend','PLT_Trend','USDI_Price','GDX_Close','SMA','Upper_band','RSI','Open_Close']]\nfeature_selected_validation_X = validation_X[['Open','High','Low','OF_Trend','USB_Trend','PLT_Trend','USDI_Price','GDX_Close','SMA','Upper_band','RSI','Open_Close']]\ndisplay(feature_selected.head())\ndisplay(feature_selected_validation_X.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:16:08.493076Z","iopub.execute_input":"2021-07-20T15:16:08.49344Z","iopub.status.idle":"2021-07-20T15:16:08.529662Z","shell.execute_reply.started":"2021-07-20T15:16:08.493411Z","shell.execute_reply":"2021-07-20T15:16:08.529076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":" for train_index, test_index in ts_split.split(feature_selected):\n        X_train, X_test = feature_selected[:len(train_index)], feature_selected[len(train_index): (len(train_index)+len(test_index))]\n        y_train, y_test = target_adj_close[:len(train_index)].values.ravel(), target_adj_close[len(train_index): (len(train_index)+len(test_index))].values.ravel()\n     ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:16:14.311328Z","iopub.execute_input":"2021-07-20T15:16:14.311819Z","iopub.status.idle":"2021-07-20T15:16:14.321231Z","shell.execute_reply.started":"2021-07-20T15:16:14.311776Z","shell.execute_reply":"2021-07-20T15:16:14.320324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## validation Feature Selected Benchmark & Solution Model","metadata":{}},{"cell_type":"code","source":"def feature_selected_validate_result(model, model_name):\n    predicted = model.predict(feature_selected_validation_X)\n    \n    RSME_score = np.sqrt(mean_squared_error(validation_y, predicted))\n    R2_score = r2_score(validation_y, predicted)\n    \n    print(model_name + '\\n')\n    print('RMSE: ', RSME_score)\n    print('R2 score: ', R2_score)\n    print('----------------------')\n\n\nprint('---------Benchmark-------------')  \ndt = DecisionTreeRegressor(random_state=0)\nbenchmark_dt_fs = dt.fit(X_train,y_train)\nfeature_selected_validate_result(benchmark_dt_fs, 'Decision Tree')\n\nfeature_selected_solution_models = {}\n \nprint('--------Solution Models--------------')  \n# Random Forest\nrandom_forest_clf_fs = RandomForestRegressor(random_state=0,\n                                             max_depth=3,\n                                             max_features='auto',\n                                             n_estimators=10\n)\nrandom_forest_parameters = {\n    'n_estimators':[10, 50, 100],\n    'max_features':['auto','sqrt','log2'],\n    'max_depth':[3, 5, 7],\n}\ngrid_search_RF_fs = GridSearchCV(estimator=random_forest_clf_fs,\n                           param_grid=random_forest_parameters,\n                           cv=ts_split,\n)\ngrid_search_RF_fs.fit(X_train, y_train)\nfeature_selected_validate_result(grid_search_RF_fs,'Feature selected RandomForest GS')\nfeature_selected_solution_models['FS_RandomForest'] = grid_search_RF_fs\n\n# Linear SVR\nlinear_svr_fs = SVR(\n                          C=50.0,\n                          epsilon=0,kernel='linear')\nlinear_svr_clf_fs = linear_svr_fs.fit(X_train,y_train)\nfeature_selected_validate_result(linear_svr_clf_fs,'Feature selected LSVR')\nfeature_selected_solution_models['FS_LSVR'] = linear_svr_clf_fs\n\n\n# lasso\nlasso_fs = LassoCV(n_alphas=1000, max_iter=3000, random_state=0)\nlasso_clf_fs = lasso_fs.fit(X_train,y_train)\nfeature_selected_validate_result(lasso_clf_fs,'Feature selected LassoCV')\nfeature_selected_solution_models['FS_Lasso'] = lasso_clf_fs\n\n# Ridge\nridge_fs = RidgeCV(gcv_mode='auto')\nridge_clf_fs = ridge_fs.fit(X_train,y_train)\nfeature_selected_validate_result(ridge_clf_fs,'Feature selected RidgeCV')\nfeature_selected_solution_models['FS_RidgeCV'] = ridge_clf_fs\n\n# bayesian ridge\nbay = linear_model.BayesianRidge()\nbay_feat_fs = bay.fit(X_train,y_train)\nfeature_selected_validate_result(bay_feat_fs,'Feature selected BayRidge')\nfeature_selected_solution_models['Bay_Ridge'] = bay_feat_fs\n\n#Gradient Boosting\nregr =GradientBoostingRegressor(n_estimators=70, learning_rate=0.1,max_depth=4, random_state=0, loss='ls')\nGB_fs = regr.fit(X_train,y_train)\nfeature_selected_validate_result(GB_fs,'Feature selected GB')\nfeature_selected_solution_models['GB_FS'] = GB_fs\n\n#SGD\n\nsgd =SGDRegressor(max_iter=1000, tol=1e-3,loss='squared_epsilon_insensitive',penalty='l1',alpha=0.1)\nsgd_fs = sgd.fit(X_train,y_train)\nfeature_selected_validate_result(sgd_fs,'Feature selected SGD')\nfeature_selected_solution_models['sgd_fs'] = sgd_fs\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:16:16.417592Z","iopub.execute_input":"2021-07-20T15:16:16.417895Z","iopub.status.idle":"2021-07-20T15:16:54.049733Z","shell.execute_reply.started":"2021-07-20T15:16:16.417869Z","shell.execute_reply":"2021-07-20T15:16:54.049146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Review","metadata":{}},{"cell_type":"code","source":"FS_RMSE_scores = {}\n\ndef fs_model_review(models):\n    fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(16, 16))\n\n    #plot benchmark model\n    benchmark_dt_predicted = benchmark_dt_fs.predict(feature_selected_validation_X)\n    benchmark_RSME_score = np.sqrt(mean_squared_error(validation_y, benchmark_dt_predicted))\n    FS_RMSE_scores['Benchmark'] = benchmark_RSME_score\n    \n    axes[0,0].plot(validation_y.index, benchmark_dt_predicted,'y', label='Predict')\n    axes[0,0].plot(validation_y.index, validation_y,'b', label='Actual')\n    axes[0,0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n    axes[0,0].xaxis.set_major_locator(mdates.MonthLocator())\n    axes[0,0].set_ylabel('Price')\n    axes[0,0].set_title(\"Benchmark Predict's RMSE Error: \" +\"{0:.2f}\".format(benchmark_RSME_score))\n    axes[0,0].legend(loc='upper right')\n    \n    #plot block\n    ax_x = 0\n    ax_y = 1\n    #plot solution model\n    for name, model in models.items():\n        predicted = model.predict(feature_selected_validation_X)\n        RSME_score = np.sqrt(mean_squared_error(validation_y, predicted))\n\n        R2_score = r2_score(validation_y, predicted)\n    \n        axes[ax_x][ax_y].plot(validation_y.index, predicted,'y', label='Predict')\n        axes[ax_x][ax_y].plot(validation_y.index, validation_y,'b', label='Actual')\n        axes[ax_x][ax_y].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n        axes[ax_x][ax_y].xaxis.set_major_locator(mdates.MonthLocator())\n        axes[ax_x][ax_y].set_ylabel('Price')\n        axes[ax_x][ax_y].set_title(name + \"'s RMSE Error: \" +\"{0:.2f}\".format(RSME_score))\n        axes[ax_x][ax_y].legend(loc='upper right')\n        FS_RMSE_scores[name] = RSME_score\n        if ax_x <=2:\n            if ax_y < 2:\n                ax_y += 1\n            else:\n                ax_x += 1\n                ax_y = 0\n    plt.show()\n\nfs_model_review(feature_selected_solution_models)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:16:58.675279Z","iopub.execute_input":"2021-07-20T15:16:58.675719Z","iopub.status.idle":"2021-07-20T15:16:59.841481Z","shell.execute_reply.started":"2021-07-20T15:16:58.675693Z","shell.execute_reply":"2021-07-20T15:16:59.840827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparison of RMSE of Feature selected models and Original Features model","metadata":{}},{"cell_type":"code","source":"\nfs_model_names = []\nfs_model_values = []\nfor name, value in FS_RMSE_scores.items():\n    fs_model_names.append(name)\n    fs_model_values.append(value)\n\nfs_model_values = np.array(fs_model_values)\nfs_model_names = np.array(fs_model_names)\n\nfs_indices = np.argsort(fs_model_values)\nfs_columns = fs_model_names[fs_indices[:8]]\nfs_values = fs_model_values[fs_indices][:8]\norigin_values = model_values[fs_indices][:8]\n\nfig = plt.figure(figsize = (16,8))\nplt.bar(np.arange(8) - 0.2 , origin_values ,width = 0.4, align=\"center\", color = '#b2b2ff', label = \"Original\")\nplt.bar(np.arange(8), fs_values ,width = 0.4, align=\"center\", color = '#3232ff', label = \"Feature Selected\")\nplt.xticks(np.arange(8), fs_columns)\nplt.xlabel('Model')\nplt.ylabel('RMSE')\nplt.title('RMSE compare after feature selection')\nplt.legend(loc = 'upper center')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:05.434194Z","iopub.execute_input":"2021-07-20T15:17:05.434666Z","iopub.status.idle":"2021-07-20T15:17:05.633435Z","shell.execute_reply.started":"2021-07-20T15:17:05.434639Z","shell.execute_reply":"2021-07-20T15:17:05.632729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As we have seen from the above plot 3 Feature selected models performs better in RMSE error reduction and Feature selected Linear SVR is the best as it has RMSE of 0.716 in feature selected model and 0.741 with all features model. Also Lasso cv and Bayesian Ridge performs slightly better from original features model where as Ridge cv shows no improvement from features model.Where as four model performance degrades  after feature selection in which benchmark model has highest RMSE error and SGD model degrades most in comparison to others.**","metadata":{}},{"cell_type":"markdown","source":"# Ensemble Solution\n\nSo now we will ensemble top three performing models i.e, in case of all the features model Lasso,Bayesian ridge and Ridge are the best performing models so we will ensemble these three models while in case of feature selected models we will combine Lasso,Bayesian Ridge and Linear SVR and will compare all the feature ensemble models with feature selected ensemble models.","metadata":{}},{"cell_type":"code","source":"# Choosing the top three performing models to ensemble them\nensemble_solution_models = [lasso_clf_feat, bay_feat, ridge_clf_feat]\nclass EnsembleSolution:\n    models = []\n    def __init__(self, models):\n        self.models = models\n    def fit(self, X, y):\n        for i in self.models:\n            i.fit(X, y)\n    def predict(self, X):\n        result = 0\n        for i in self.models:\n            result = result + i.predict(X)\n        \n        result = result / len(self.models)\n        \n        return result","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:23.277175Z","iopub.execute_input":"2021-07-20T15:17:23.277487Z","iopub.status.idle":"2021-07-20T15:17:23.283658Z","shell.execute_reply.started":"2021-07-20T15:17:23.27746Z","shell.execute_reply":"2021-07-20T15:17:23.282859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Ensemble Solution Model with Original features\")\nEnsembleModel = EnsembleSolution(ensemble_solution_models)\nvalidate_result(EnsembleModel,'EnsembleSolution')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:24.132748Z","iopub.execute_input":"2021-07-20T15:17:24.133054Z","iopub.status.idle":"2021-07-20T15:17:24.283273Z","shell.execute_reply.started":"2021-07-20T15:17:24.133027Z","shell.execute_reply":"2021-07-20T15:17:24.28245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensemble solution with all features shows best result (with RMSE 0.699 and R2 score of 0.887) in comparison with other solution models.","metadata":{}},{"cell_type":"code","source":"ensemble_solution_model_fs = [lasso_clf_fs,bay_feat_fs,linear_svr_clf_fs]\n\nprint(\"Ensemble Solution Model with Selected features\")\nEnsembleModel_fs = EnsembleSolution(ensemble_solution_model_fs)\nfeature_selected_validate_result(EnsembleModel_fs,'EnsembleSolution with FS')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:29.212023Z","iopub.execute_input":"2021-07-20T15:17:29.212383Z","iopub.status.idle":"2021-07-20T15:17:29.228657Z","shell.execute_reply.started":"2021-07-20T15:17:29.212353Z","shell.execute_reply":"2021-07-20T15:17:29.227835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensemble solution with feature selection has better solution (RMSE 0.711 and  R2score 0.884 ) but Lasso has best performance (RMSE - 0.709 and R2 score 0.884)","metadata":{}},{"cell_type":"markdown","source":"## Train Model Multiple Times\nBy the train_reg_multipletimes function.This function would train the model several times (I choosed 7 times ), and use different parameters on TimeSeriesSplit in each time, average the R2 and RMSE.\nI will apply this function on Benchmark model and on top performing solution models with all features which are Linear SVR, Lasso, Ridge and Bayesian ridge and compare the same.","metadata":{}},{"cell_type":"code","source":"def train_reg_multipletimes(model, times):\n    total_rmse = 0\n    total_r2 = 0\n    for i in range(times):\n        reg = model\n        for train_index, test_index in TimeSeriesSplit(n_splits=i+2).split(feature_minmax_transform):\n            X_train, X_test = feature_minmax_transform[:len(train_index)], feature_minmax_transform[len(train_index): (len(train_index)+len(test_index))]\n            y_train, y_test = target_adj_close[:len(train_index)].values.ravel(), target_adj_close[len(train_index): (len(train_index)+len(test_index))].values.ravel()\n            reg.fit(X_train, y_train)\n        predicted = reg.predict(validation_X)\n        rmse, r2 = print_result(validation_y, predicted, [0,len(validation_y)])\n        total_rmse += rmse\n        total_r2 += r2\n    return total_rmse / times, total_r2 / times\n\ndef print_result(actual, predict, index):\n    RMSE_score = np.sqrt(mean_squared_error(actual, predict))\n    print('From {} to {}'.format(index[0],index[-1]))\n    print('RMSE: ', RMSE_score)\n    R2_score = r2_score(actual, predict)\n    print('R2 score: ', R2_score)\n    print('---------------------')\n    return RMSE_score, R2_score","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:33.876841Z","iopub.execute_input":"2021-07-20T15:17:33.877171Z","iopub.status.idle":"2021-07-20T15:17:33.886253Z","shell.execute_reply.started":"2021-07-20T15:17:33.877133Z","shell.execute_reply":"2021-07-20T15:17:33.88532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Benchmark')\nt_multiple_benchmark_RMSE,t_multiple_benchmark_R2 = train_reg_multipletimes(benchmark_dt, 7)\nprint('RMSE: {} //  R2: {}\\n'.format(t_multiple_benchmark_RMSE, t_multiple_benchmark_R2))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:35.6638Z","iopub.execute_input":"2021-07-20T15:17:35.664173Z","iopub.status.idle":"2021-07-20T15:17:37.429838Z","shell.execute_reply.started":"2021-07-20T15:17:35.664104Z","shell.execute_reply":"2021-07-20T15:17:37.42889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('LSVR')\nt_multiple_LSVR_RMSE,t_multiple_LSVR_R2 = train_reg_multipletimes(linear_svr_clf_feat, 7)\nprint(' RMSE: {} //  R2: {}'.format(t_multiple_LSVR_RMSE, t_multiple_LSVR_R2))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:43.464386Z","iopub.execute_input":"2021-07-20T15:17:43.464698Z","iopub.status.idle":"2021-07-20T15:17:47.840028Z","shell.execute_reply.started":"2021-07-20T15:17:43.464673Z","shell.execute_reply":"2021-07-20T15:17:47.839181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Lasso')\nt_multiple_lasso_RMSE,t_multiple_lasso_R2 = train_reg_multipletimes(lasso_clf_feat, 7)\nprint(' RMSE: {} //  R2: {}'.format(t_multiple_lasso_RMSE, t_multiple_lasso_R2))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:17:47.841397Z","iopub.execute_input":"2021-07-20T15:17:47.841696Z","iopub.status.idle":"2021-07-20T15:18:25.956414Z","shell.execute_reply.started":"2021-07-20T15:17:47.841657Z","shell.execute_reply":"2021-07-20T15:18:25.955601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Ridge')\nt_multiple_ridge_RMSE,t_multiple_ridge_R2 = train_reg_multipletimes(ridge_clf_feat, 7)\nprint(' RMSE: {} //  R2: {}'.format(t_multiple_ridge_RMSE, t_multiple_ridge_R2))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:18:25.95778Z","iopub.execute_input":"2021-07-20T15:18:25.958027Z","iopub.status.idle":"2021-07-20T15:18:26.552261Z","shell.execute_reply.started":"2021-07-20T15:18:25.958003Z","shell.execute_reply":"2021-07-20T15:18:26.551277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('BayRidge')\nt_multiple_bayridge_RMSE,t_multiple_bayridge_R2 = train_reg_multipletimes(bay_feat, 7)\nprint(' RMSE: {} //  R2: {}'.format(t_multiple_bayridge_RMSE, t_multiple_bayridge_R2))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:18:26.55698Z","iopub.execute_input":"2021-07-20T15:18:26.559276Z","iopub.status.idle":"2021-07-20T15:18:27.25848Z","shell.execute_reply.started":"2021-07-20T15:18:26.559228Z","shell.execute_reply":"2021-07-20T15:18:27.257429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Ensemble')\nt_multiple_ensemble_RMSE,t_multiple_ensemble_R2 = train_reg_multipletimes(EnsembleSolution(ensemble_solution_models), 7)\nprint(' RMSE: {} //  R2: {}\\n'.format(t_multiple_ensemble_RMSE, t_multiple_ensemble_R2))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:18:27.260309Z","iopub.execute_input":"2021-07-20T15:18:27.26104Z","iopub.status.idle":"2021-07-20T15:19:06.530814Z","shell.execute_reply.started":"2021-07-20T15:18:27.260983Z","shell.execute_reply":"2021-07-20T15:19:06.529885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_validate(model, ts_split):\n    clf = model\n    total_rmse = 0\n    total_r2 = 0\n    count = 0\n    for train_index, test_index in ts_split.split(validation_X):\n        X_test1, X_test2 = validation_X[:len(train_index)], validation_X[len(train_index): (len(train_index)+len(test_index))]\n        y_test1, y_test2 = validation_y[:len(train_index)].values.ravel(), validation_y[len(train_index): (len(train_index)+len(test_index))].values.ravel()\n        predicted_test1 = clf.predict(X_test1)\n        temp1_RMSE, temp1_R2 = print_result(y_test1, predicted_test1, train_index)\n\n        predicted_test2 = clf.predict(X_test2)\n        temp2_RMSE, temp2_R2 = print_result(y_test2, predicted_test2, test_index)\n        \n        total_rmse += temp1_RMSE + temp2_RMSE\n        total_r2 += temp1_R2 + temp2_R2\n        count += 2\n    return total_rmse / count, total_r2 / count\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:10.379663Z","iopub.execute_input":"2021-07-20T15:19:10.379962Z","iopub.status.idle":"2021-07-20T15:19:10.387003Z","shell.execute_reply.started":"2021-07-20T15:19:10.379936Z","shell.execute_reply":"2021-07-20T15:19:10.386075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"timeseries_cv = TimeSeriesSplit(n_splits=10)\ntest_bench__RMSE, test_bench_R2 = cross_validate(benchmark_dt,timeseries_cv)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:12.473238Z","iopub.execute_input":"2021-07-20T15:19:12.473567Z","iopub.status.idle":"2021-07-20T15:19:12.550134Z","shell.execute_reply.started":"2021-07-20T15:19:12.47354Z","shell.execute_reply":"2021-07-20T15:19:12.54924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_lsvr__RMSE, test_lsvr_R2 = cross_validate(lsvr_grid_search_feat,timeseries_cv)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:19.529589Z","iopub.execute_input":"2021-07-20T15:19:19.529901Z","iopub.status.idle":"2021-07-20T15:19:19.684165Z","shell.execute_reply.started":"2021-07-20T15:19:19.529874Z","shell.execute_reply":"2021-07-20T15:19:19.683291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ridge__RMSE, test_ridge_R2 = cross_validate(ridge_clf_feat,timeseries_cv)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:20.778203Z","iopub.execute_input":"2021-07-20T15:19:20.778565Z","iopub.status.idle":"2021-07-20T15:19:20.854016Z","shell.execute_reply.started":"2021-07-20T15:19:20.778536Z","shell.execute_reply":"2021-07-20T15:19:20.853053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_lasso__RMSE, test_lasso_R2 = cross_validate(lasso_clf_feat,timeseries_cv)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:21.768718Z","iopub.execute_input":"2021-07-20T15:19:21.769043Z","iopub.status.idle":"2021-07-20T15:19:21.843338Z","shell.execute_reply.started":"2021-07-20T15:19:21.769016Z","shell.execute_reply":"2021-07-20T15:19:21.842457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_bay_RMSE, test_bay_R2 = cross_validate(bay_feat,timeseries_cv)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:22.808574Z","iopub.execute_input":"2021-07-20T15:19:22.80895Z","iopub.status.idle":"2021-07-20T15:19:22.896401Z","shell.execute_reply.started":"2021-07-20T15:19:22.808918Z","shell.execute_reply":"2021-07-20T15:19:22.888244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ensemble_RMSE, test_ensemble_R2 = cross_validate(EnsembleSolution(ensemble_solution_models),timeseries_cv)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:23.87787Z","iopub.execute_input":"2021-07-20T15:19:23.878212Z","iopub.status.idle":"2021-07-20T15:19:24.035861Z","shell.execute_reply.started":"2021-07-20T15:19:23.878184Z","shell.execute_reply":"2021-07-20T15:19:24.035131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Benchmark RMSE: {} // Benchmark R2: {}'.format(test_bench__RMSE, test_bench_R2))\nprint('LSVR RMSE: {} // LSVR R2: {}'.format(test_lsvr__RMSE, test_lsvr_R2))\nprint('Lasso RMSE: {} // Lasso R2: {}'.format(test_lasso__RMSE, test_lasso_R2))\nprint('bayesian ridge RMSE: {} // Bayesian ridge R2: {}'.format(test_bay_RMSE, test_bay_R2))\n\nprint('Ensemble RMSE: {} // Ensemble R2: {}'.format(test_ensemble_RMSE, test_ensemble_R2))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T15:19:25.182209Z","iopub.execute_input":"2021-07-20T15:19:25.182515Z","iopub.status.idle":"2021-07-20T15:19:25.189223Z","shell.execute_reply.started":"2021-07-20T15:19:25.182491Z","shell.execute_reply":"2021-07-20T15:19:25.188348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**hope you like this kernel. please upvote to show your support**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}